{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56ff0be9-5327-4961-beed-184d0395fda4",
   "metadata": {},
   "source": [
    "## Modeling NBA Data\n",
    "<!-- </br> -->\n",
    "\n",
    "#### Overview:\n",
    "- In `src/eda.ipynb`, it appears as though there are several variables which have strong a relationship to `fpts`, the target variable I would like to predict.\n",
    "- However, most of these variables occur with `fpts`, and are not actually known prior to the game.\n",
    "- While I could input medians/means of these valuables and use them as inputs, that then causes a slew of other problems mainly stemming from various forms of bias.\n",
    "- Instead, I will be creating a Classification Model to determine likely outcomes without having to predict exact values.\n",
    "\n",
    "#### Goals:\n",
    "- The first part of this notebook will contain cleaning the data so as to isolate the features I want and discard any features I do not think are necessary.\n",
    "- This will be an iterative process, so I may return to include more features later on, therefore I will write functions to accomodate this.\n",
    "</br>\n",
    "\n",
    "- Next, I will classify the outcomes for player performances.\n",
    "- I will classify players into 3 bins to start:\n",
    "    - ***Bust*: Performance in which a player achieved worse than a 40% outcome.**\n",
    "    - ***Neutral*: Performance in which a player achieved a 40%-75% outcome.**\n",
    "    - ***Boom*: Performance in which a player achieved better than a 75% outcome.**\n",
    "- *Notes:*\n",
    "    - *The reason for doing it this way is because in Fantasy Sports, you would really like to predict when players will have \"Boom\" outcomes in order to perform better than other contestants.*\n",
    "    - *These three categories are not evenly distributed, I don't think this will be an issue but may need to revisit,*\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd5b20f-6ee3-4790-bc26-ec329604bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Custom settings for libraries used\n",
    "import settings.custom\n",
    "\n",
    "# Custom functions for dealing with local files\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61c09d9-ceea-44ca-9d49-de33c502403e",
   "metadata": {},
   "source": [
    "#### Helper Functions\n",
    "\n",
    "##### Functions that are not main part of code, but are used to achieve desired result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ebae895-a240-48b8-a4ba-d5c5a957fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Sequence\n",
    "\n",
    "def flatten(seq: Sequence[Sequence[Any]]) -> list[Any,...]:\n",
    "    \"\"\"\n",
    "    Converts a nested or 2d sequence of any kind into a 1d list\n",
    "    Example: flatten([('foo', 'bar'), ('baz', 'qux')]) -> ['foo', 'bar', 'baz', 'qux']\n",
    "    \"\"\"\n",
    "    return [element for inner_seq in seq for element in inner_seq]\n",
    "\n",
    "def percentile(n: int) -> float:\n",
    "    \"\"\"\n",
    "    Calculates n% outcome for players, designed for use in .agg\n",
    "    Example: df.groupby('name')['fpts'].agg([percentile(0), percentile(50), percentile(100)])\n",
    "         -> Returns 3 columns, indexed by name corresponding to following outcomes: 0% (minimum), 50% (median), 100% (maxium)\n",
    "         -> Common usage will be 25% which roughly corresponds to floor and 75% which roughly corresponds to ceiling\n",
    "    \"\"\"\n",
    "    def percentile_(arr):\n",
    "        return np.percentile(arr, n)\n",
    "\n",
    "    # Can create custom labels if wanted, as of now decided against\n",
    "    # label = {25: 'floor', 50: 'median', 75: 'ceiling'}.get(n, f'{n}%')\n",
    "    # percentile_.__name__ = label\n",
    "    percentile_.__name__ = f'{n}%'\n",
    "    return percentile_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "82076386-5e1d-4276-85de-17c58153f1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset_for_model(season: str, **kwargs) -> None:\n",
    "    \"\"\"\n",
    "    This function will do some basic cleaning and perform the classification as indicated above.\n",
    "    Defaults to DraftKings Fantasy Points, but simply need to pass kwarg specifying site='fanduel' to change.\n",
    "    In order to accomplish this, will use the custom function created in the above cell to calculate % outcomes for each player.\n",
    "    As of right now, will not worry too much about exceptions for odd lineups or missing players, etc. But may revisit to adjust later.\n",
    "    Instead of returning pandas DataFrame, I will save this as a new .csv file labeled clean.\n",
    "    \"\"\"\n",
    "\n",
    "    site = kwargs.get('site', 'draftkings')\n",
    "    df: pd.DataFrame = utilities.load_raw_dataset(season, site=site)\n",
    "\n",
    "    # Will not specify target at this point, just all features want included\n",
    "    # To start will only include information one would know before a game. \n",
    "    # Will also include fantasy points (fpts) and minutes played (mp) and usage (usg) as they are also important and could be used with fantasy points\n",
    "    features: list[str,...] = sum([\n",
    "        ['name', 'starter', 'team', 'opp', 'home', 'mp', 'usg', 'fpts'],\n",
    "        kwargs.get('features', [])\n",
    "    ], [])\n",
    "\n",
    "    # Truncate DataFrame to only include above features\n",
    "    # Will also create a new column: fantasy points per minute (fppm) as another possible metric to use.\n",
    "    # Maps well to player's fantasy point production / efficiency in cases where minutes played are irregular.\n",
    "    df = (df\n",
    "          [features]\n",
    "          .assign(fppm=lambda df_: df_.fpts / df_.mp)\n",
    "         )\n",
    "\n",
    "\n",
    "    # In order to classify outcomes, first need to make data structure containing cutoffs for each player's outcomes\n",
    "    # As of right now, will also get rid of players who have not played at least 5 games of 8 or more minutes. (Tweak later)\n",
    "\n",
    "    \n",
    "\n",
    "    bust = kwargs.get('bust', 40)\n",
    "    boom = kwargs.get('boom', 75)\n",
    "    \n",
    "    outcomes = (df\n",
    "                .loc[df['mp'] >= 8.0]\n",
    "                .groupby('name')\n",
    "                ['fpts']\n",
    "                .agg(['count', percentile(bust), percentile(boom)])\n",
    "               )\n",
    "\n",
    "    # Get rid of players who don't meet sample size requirements\n",
    "    drop_names = flatten([\n",
    "        # Have not played enough games of more than 8 minutes\n",
    "        list(outcomes.loc[outcomes['count'] < 5].index),\n",
    "        # Have not played any games of more than 8 minutes\n",
    "        [name_ for name_ in df['name'].drop_duplicates() if name_ not in outcomes.index]\n",
    "    ])\n",
    "\n",
    "    df = df.loc[df['name'].isin(drop_names) == False]\n",
    "\n",
    "    for name in outcomes.index:\n",
    "        # Upper boundary for bust outcome, lower boundary for boom outcome\n",
    "        # Only need these two values\n",
    "        bust_upper, boom_lower = [outcomes.loc[name, f'{result}%'] for result in (bust, boom)]\n",
    "        df.loc[(df['name'] == name) & (df['fpts'] < bust_upper), 'outcome'] = 'bust'\n",
    "        df.loc[(df['name'] == name) & (df['fpts'] >= bust_upper) & (df['fpts'] <= boom_lower), 'outcome'] = 'neutral'\n",
    "        df.loc[(df['name'] == name) & (df['fpts'] > boom_lower), 'outcome'] = 'boom'\n",
    "\n",
    "    utilities.save_clean_dataset(df, season, site)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b46b1a66-7e70-44e6-95c1-872ba2a92619",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEASON = '2023-2024'\n",
    "SITE = 'draftkings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "590bb6ef-93d0-455c-961d-c735ffda29cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_dataset_for_model(SEASON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abf648f-c47f-4960-ba02-0d4708fdb638",
   "metadata": {},
   "source": [
    "#### Quick test to view results looks good, can now move on to building model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed921dc0-49d6-40b1-9752-f23a07061119",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = utilities.load_clean_dataset(SEASON, SITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9465f9ac-14d7-4cac-b75e-6a786e4726de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>starter</th>\n",
       "      <th>team</th>\n",
       "      <th>opp</th>\n",
       "      <th>home</th>\n",
       "      <th>mp</th>\n",
       "      <th>fpts</th>\n",
       "      <th>fppm</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7478</th>\n",
       "      <td>Christian Braun</td>\n",
       "      <td>0</td>\n",
       "      <td>DEN</td>\n",
       "      <td>OKC</td>\n",
       "      <td>0</td>\n",
       "      <td>21.167</td>\n",
       "      <td>36.25</td>\n",
       "      <td>1.713</td>\n",
       "      <td>boom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3205</th>\n",
       "      <td>Isaiah Stewart</td>\n",
       "      <td>1</td>\n",
       "      <td>DET</td>\n",
       "      <td>HOU</td>\n",
       "      <td>1</td>\n",
       "      <td>28.650</td>\n",
       "      <td>26.25</td>\n",
       "      <td>0.916</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1237</th>\n",
       "      <td>Nikola Jokic</td>\n",
       "      <td>1</td>\n",
       "      <td>DEN</td>\n",
       "      <td>PHI</td>\n",
       "      <td>1</td>\n",
       "      <td>36.667</td>\n",
       "      <td>60.50</td>\n",
       "      <td>1.650</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7043</th>\n",
       "      <td>Kevin Durant</td>\n",
       "      <td>1</td>\n",
       "      <td>PHO</td>\n",
       "      <td>CHA</td>\n",
       "      <td>1</td>\n",
       "      <td>38.683</td>\n",
       "      <td>53.00</td>\n",
       "      <td>1.370</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6788</th>\n",
       "      <td>Trey Murphy</td>\n",
       "      <td>0</td>\n",
       "      <td>NO</td>\n",
       "      <td>MEM</td>\n",
       "      <td>1</td>\n",
       "      <td>35.933</td>\n",
       "      <td>24.75</td>\n",
       "      <td>0.689</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15702</th>\n",
       "      <td>Scottie Barnes</td>\n",
       "      <td>1</td>\n",
       "      <td>TOR</td>\n",
       "      <td>ATL</td>\n",
       "      <td>0</td>\n",
       "      <td>37.600</td>\n",
       "      <td>42.50</td>\n",
       "      <td>1.130</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2374</th>\n",
       "      <td>Dennis Smith</td>\n",
       "      <td>0</td>\n",
       "      <td>BKN</td>\n",
       "      <td>ORL</td>\n",
       "      <td>1</td>\n",
       "      <td>20.700</td>\n",
       "      <td>39.75</td>\n",
       "      <td>1.920</td>\n",
       "      <td>boom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2133</th>\n",
       "      <td>Stanley Umude</td>\n",
       "      <td>0</td>\n",
       "      <td>DET</td>\n",
       "      <td>LAL</td>\n",
       "      <td>1</td>\n",
       "      <td>20.183</td>\n",
       "      <td>18.75</td>\n",
       "      <td>0.929</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11745</th>\n",
       "      <td>Toumani Camara</td>\n",
       "      <td>1</td>\n",
       "      <td>POR</td>\n",
       "      <td>SA</td>\n",
       "      <td>1</td>\n",
       "      <td>21.067</td>\n",
       "      <td>9.25</td>\n",
       "      <td>0.439</td>\n",
       "      <td>bust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6378</th>\n",
       "      <td>Franz Wagner</td>\n",
       "      <td>1</td>\n",
       "      <td>ORL</td>\n",
       "      <td>BOS</td>\n",
       "      <td>0</td>\n",
       "      <td>34.317</td>\n",
       "      <td>34.25</td>\n",
       "      <td>0.998</td>\n",
       "      <td>bust</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  name  starter team  opp  home      mp   fpts   fppm  outcome\n",
       "7478   Christian Braun        0  DEN  OKC     0  21.167  36.25  1.713     boom\n",
       "3205    Isaiah Stewart        1  DET  HOU     1  28.650  26.25  0.916  neutral\n",
       "1237      Nikola Jokic        1  DEN  PHI     1  36.667  60.50  1.650  neutral\n",
       "7043      Kevin Durant        1  PHO  CHA     1  38.683  53.00  1.370  neutral\n",
       "6788       Trey Murphy        0   NO  MEM     1  35.933  24.75  0.689  neutral\n",
       "15702   Scottie Barnes        1  TOR  ATL     0  37.600  42.50  1.130  neutral\n",
       "2374      Dennis Smith        0  BKN  ORL     1  20.700  39.75  1.920     boom\n",
       "2133     Stanley Umude        0  DET  LAL     1  20.183  18.75  0.929  neutral\n",
       "11745   Toumani Camara        1  POR   SA     1  21.067   9.25  0.439     bust\n",
       "6378      Franz Wagner        1  ORL  BOS     0  34.317  34.25  0.998     bust"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9964a65a-72af-43d3-8200-e15ca8df7839",
   "metadata": {},
   "source": [
    "##### Model Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "271df233-8e5d-4042-b83e-87e3a9e4640f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold #, GridSearchCV\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    mean_squared_error\n",
    ")\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import (\n",
    "    MinMaxScaler,\n",
    "    Normalizer,\n",
    "    OneHotEncoder,\n",
    "    PolynomialFeatures,\n",
    "    StandardScaler\n",
    ")\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "006729de-2462-4f60-98c7-d8aa75fb3fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_confusion_matrix(cm: np.ndarray) -> dict[[str], int]:\n",
    "    \"\"\"\n",
    "    Confusion matrix has form:\n",
    "    \n",
    "    bust perceived as bust         bust perceived as neutral         bust perceived as boom\n",
    "    neutral perceived as bust      neutral perceived as neutral      neutral perceived as boom\n",
    "    boom perceived as bust         boom perceived as neutral         boom perceived as boom\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    flatten = lambda nested_list: tuple([value for nested in nested_list for value in nested])    \n",
    "    true_positive, false_negative, false_positive, true_negative = flatten(cm.tolist())\n",
    "\n",
    "    return {\n",
    "        'Bust perceived as Bust':\n",
    "        'Bust perceived as Neutral':\n",
    "        'Bust perceived as Boom'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c7f50cba-f44c-47e9-89b1-d677168c7341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(season: str, site: str, **kwargs):\n",
    "    \"\"\"\n",
    "    Runs an XGBClassifier Model on dataset to predict players outcomes\n",
    "    Will build a class with more flushed out functionality once basic model is working.\n",
    "    \"\"\"\n",
    "\n",
    "    df = utilities.load_clean_dataset(season, site)\n",
    "    \n",
    "    target = 'outcome'\n",
    "    features = kwargs.get(\n",
    "        'features',\n",
    "        [column for column in df if column not in ('name', 'mp', 'fpts', 'fppm', target)]\n",
    "    )\n",
    "\n",
    "    cat_features = list(df[features].select_dtypes(exclude='number').columns)\n",
    "    num_features = list(df[features].select_dtypes(include='number').columns)\n",
    "    bin_features = [feature for feature in num_features if df[feature].value_counts().shape[0] == 2]\n",
    "\n",
    "    for feature in bin_features:\n",
    "        df[feature] = df[feature].astype('uint8')\n",
    "        # if feature in num_features:\n",
    "        #     num_features.remove(feature)\n",
    "\n",
    "    target_mapping = {'bust': 0, 'neutral': 1, 'boom': 2}\n",
    "\n",
    "    df[target] = df[target].map(lambda oc: target_mapping[oc])\n",
    "\n",
    "    X = df[features]\n",
    "    y = df[target]\n",
    "\n",
    "    # Column Transformers\n",
    "    ct = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('ohe', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_features),\n",
    "            ('ss', StandardScaler(), num_features),\n",
    "            ('polynomial', PolynomialFeatures(include_bias=False), num_features) # Better training data score but worse overall,\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "\n",
    "    X_transformed = ct.fit_transform(X)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_transformed, y, test_size=0.2, train_size=0.8, random_state=42)\n",
    "\n",
    "    clf = xgb.XGBClassifier()\n",
    "\n",
    "    clf.fit(X_train, y_train)\n",
    "\n",
    "    # Output model results\n",
    "    print(f'\\nModel score for training data for {target}: {clf.score(X_train, y_train):.4f}')\n",
    "    print(f'Model score for testing data for {target}: {clf.score(X_test, y_test):.4f}\\n') # --> returns identical result to sklearn.metrics.accuracy_score(y_test, clf.predict(X_test))\n",
    "\n",
    "    cv_scores = cross_val_score(clf, X_train, y_train, cv=5)\n",
    "    print(f'Mean cross-validation score: {cv_scores.mean():.4f}')\n",
    "\n",
    "    # Does almost the same as above but takes average of K-separate cross_validations --> ideally want pretty similar result\n",
    "    kfold = KFold(n_splits=10, shuffle=True)\n",
    "    kf_cv_scores = cross_val_score(clf, X_train, y_train, cv=kfold)\n",
    "    print(f'K-fold CV average score: {kf_cv_scores.mean():.4f}')\n",
    "\n",
    "    y_pred = clf.predict(X_test)\n",
    "\n",
    "    print('\\nClassification Report:')\n",
    "    print(classification_report(y_test, y_pred, target_names=target_mapping.keys()))\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d173c5cc-e683-4d8e-b3af-c67da6637bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model score for training data for outcome: 0.5498\n",
      "Model score for testing data for outcome: 0.4442\n",
      "\n",
      "Mean cross-validation score: 0.4427\n",
      "K-fold CV average score: 0.4438\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bust       0.49      0.75      0.59      1519\n",
      "     neutral       0.36      0.23      0.28      1127\n",
      "        boom       0.32      0.15      0.20       740\n",
      "\n",
      "    accuracy                           0.44      3386\n",
      "   macro avg       0.39      0.37      0.36      3386\n",
      "weighted avg       0.41      0.44      0.40      3386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_model(SEASON, SITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d27a3e27-1ba4-485b-90f2-e59c99977ef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model score for training data for outcome: 0.5422\n",
      "Model score for testing data for outcome: 0.4421\n",
      "\n",
      "Mean cross-validation score: 0.4424\n",
      "K-fold CV average score: 0.4397\n",
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        bust       0.48      0.74      0.59      1519\n",
      "     neutral       0.36      0.24      0.29      1127\n",
      "        boom       0.32      0.14      0.19       740\n",
      "\n",
      "    accuracy                           0.44      3386\n",
      "   macro avg       0.39      0.37      0.36      3386\n",
      "weighted avg       0.41      0.44      0.40      3386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_model(SEASON, SITE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936ec026-75c8-48b9-aaf2-f80386d41a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
